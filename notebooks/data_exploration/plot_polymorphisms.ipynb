{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apr. 16, 2019\n",
    "Generate mutation frequencies from output.gd files. Functions adapted from ```tidy_breseq.py``` and ```plot_polymorphisms.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_outputgd_to_df(gdfile, sample_name, line, generation=np.nan, cov=False):\n",
    "    '''\n",
    "    Default returns one dataframe created from annotated.gd. All mutation rows are preserved,\n",
    "    but only selected variables from each row, namely entry type, entry id, \n",
    "    evidence id, genome id, position, mutation detail, frequency, and gene product.\n",
    "    \n",
    "    If cov=True, will return TWO dataframes, the first as above, the second reporting \n",
    "    entry type, entry id, evidence id, genome id, position,reject reasons, prediction mode, \n",
    "    polymorphism frequencies, major and minor coverages (i.e., major_cov, minor_cov), \n",
    "    total coverage (total_cov), RA coverage (new_cov), JC coverage (new_junction_read_count), \n",
    "    and MC-flanking coverage (left_outside_cov + right_outside_cov).\n",
    "    '''\n",
    "    df = pd.read_csv(gdfile, comment='#', names=range(200), dtype=str, sep='\\t')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    # https://stackoverflow.com/questions/27700591/reading-csv-files-with-messy-structure-with-pandas\n",
    "    df.rename(columns = {0: 'entry_type', 1: 'entry_id', 2: 'evidence_id', \n",
    "                         3: 'genome_id', 4: 'position', 5: 'mutation_detail'}, inplace=True)\n",
    "\n",
    "    df_mutations = df[(df['entry_type'] == 'INS') | (df['entry_type'] == 'DEL') | \n",
    "                      (df['entry_type'] == 'SNP') | (df['entry_type'] == 'SUB') | \n",
    "                      (df['entry_type'] == 'MOB') | (df['entry_type'] == 'AMP') | \n",
    "                      (df['entry_type'] == 'CON') | (df['entry_type'] == 'INV')].copy()\n",
    "    df_mutations = df_mutations.dropna(axis=1, how='all')\n",
    "    num_columns = len(df_mutations.columns)\n",
    "\n",
    "    for row in df_mutations.index:\n",
    "        #check each column\n",
    "        mut_col_index = 6\n",
    "        while mut_col_index < num_columns:\n",
    "            #1. mutation frequencies\n",
    "            if re.match('frequency=', str(df_mutations.loc[row, mut_col_index])):\n",
    "                df_mutations.loc[row, 'frequency'] = re.sub('frequency=', '', str(df_mutations.loc[row, mut_col_index]))\n",
    "                if df_mutations.loc[row, 'frequency'] == 'NA':\n",
    "                    df_mutations.loc[row, 'frequency'] = np.nan\n",
    "            mut_col_index += 1\n",
    "\n",
    "    df_mutations = df_mutations[['entry_type', 'entry_id', 'evidence_id', 'genome_id', \n",
    "                             'position', 'mutation_detail', 'frequency']].copy()\n",
    "    \n",
    "    #insert sample name, line, and generation\n",
    "    df_mutations.insert(0, 'sample', sample_name)\n",
    "    df_mutations.insert(1, 'line', line)\n",
    "    df_mutations.insert(2, 'generation', generation)\n",
    "    #set frequencies type to float\n",
    "    df_mutations['frequency'] = df_mutations['frequency'].astype(float)\n",
    "\n",
    "    if cov == True:\n",
    "        df_evidence = df[(df['entry_type'] == 'RA') | (df['entry_type'] == 'JC') | \n",
    "                         (df['entry_type'] == 'MC') | (df['entry_type'] == 'UN')].copy()\n",
    "        df_evidence.rename(columns = {6: 'REF', 7: 'ALT'}, inplace=True)\n",
    "\n",
    "        for row in df_evidence.index:\n",
    "            col_index = 8\n",
    "            while col_index < num_columns:\n",
    "                #3. polymorphism rejection reasons\n",
    "                if re.match('reject=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'reject'] = re.sub('reject=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #4. prediction type\n",
    "                elif re.match('prediction=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'prediction'] = re.sub('prediction=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #5. polymorphism mode frequencies\n",
    "                elif re.match('polymorphism_frequency=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'polymorphism_frequency'] = re.sub('polymorphism_frequency=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if df_evidence.loc[row, 'polymorphism_frequency'] == 'NA':\n",
    "                        df_evidence.loc[row, 'polymorphism_frequency'] = np.nan\n",
    "                #6. major coverage counts\n",
    "                elif re.match('major_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    major_cov = re.sub('major_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'major_cov'] = sum_cov(major_cov)\n",
    "                #7. minor coverage counts\n",
    "                elif re.match('minor_cov', str(df_evidence.loc[row, col_index])):\n",
    "                    minor_cov = re.sub('minor_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'minor_cov'] = sum_cov(minor_cov)\n",
    "                #8. total coverage counts\n",
    "                elif re.match('total_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    total_cov = re.sub('total_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'total_cov'] = sum_cov(total_cov)\n",
    "                #9. read alignment coverage counts\n",
    "                elif re.match('new_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    ra_cov = re.sub('new_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'ra_cov'] = sum_cov(ra_cov)\n",
    "                #10. new junction coverage counts\n",
    "                elif re.match('new_junction_read_count=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'jc_cov'] = re.sub('new_junction_read_count=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #11. flanking coverage counts for missing coverage evidence\n",
    "                elif re.match('left_outside_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    left_cov = re.sub('left_outside_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if left_cov == 'NA':\n",
    "                        left_cov = 0\n",
    "                    else:\n",
    "                        df_evidence.loc[row, 'left_cov'] = int(left_cov)\n",
    "                elif re.match('right_outside_cov', str(df_evidence.loc[row, col_index])):\n",
    "                    right_cov = re.sub('right_outside_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if right_cov == 'NA':\n",
    "                        right_cov = 0\n",
    "                    else:\n",
    "                        df_evidence.loc[row, 'right_cov'] = int(right_cov)\n",
    "                col_index += 1\n",
    "        \n",
    "        #set missing coverage col to 'NA' if no evidence\n",
    "        if 'left_cov' in df_evidence.columns and 'right_cov' in df_evidence.columns:\n",
    "            df_evidence[['left_cov', 'right_cov']].fillna(0)\n",
    "            df_evidence['mc_cov'] = df_evidence.left_cov + df_evidence.right_cov\n",
    "        else:\n",
    "            df_evidence['mc_cov'] = np.nan        \n",
    "        #set reject col to 'NA' when no reject reason given.\n",
    "        if 'reject' in df_evidence.columns:\n",
    "            if (df_evidence.loc[row, 'reject'] == '') & (df_evidence.loc[row, 'evidence_id'] == '.'):\n",
    "                df_evidence.loc[row, 'reject'] = np.nan\n",
    "        else:\n",
    "            df_evidence['reject'] = np.nan\n",
    "        \n",
    "        df_evidence = df_evidence[['entry_type', 'entry_id', 'genome_id', 'position', 'REF', 'ALT',\n",
    "                     'reject', 'prediction', 'polymorphism_frequency', 'major_cov', 'minor_cov', \n",
    "                     'total_cov', 'ra_cov', 'jc_cov', 'mc_cov']].copy()\n",
    "        \n",
    "        #insert sample name, line and generation\n",
    "        df_evidence.insert(0, 'sample', sample_name)\n",
    "        df_evidence.insert(1, 'line', line)\n",
    "        df_evidence.insert(2, 'generation', generation)\n",
    "        #set frequencies type to float\n",
    "        df_evidence['polymorphism_frequency'] = df_evidence['polymorphism_frequency'].astype(float)\n",
    "        \n",
    "        return df_mutations, df_evidence\n",
    "\n",
    "    else:\n",
    "        return df_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = '/Users/ymseah/Documents/gdiff_files/'\n",
    "output_directory = '/Users/ymseah/Repositories/dataviz/viz/20190416/'\n",
    "\n",
    "ancestor_df = subset_outputgd_to_df(input_directory + '0.gd', 'Ancestor', 'Ancestor', 0)\n",
    "\n",
    "#Corrected sample swap as of 4/16/19\n",
    "samples_dict = {'UA3': ['U1-100', 'UA3-300', 'U1-500', 'UE3-780', 'UE3-1000'],\n",
    "                'UE3': ['U2-100', 'UE3-300', 'U2-500', 'UA3-780', 'UA3-1000'],\n",
    "                'UR1': ['U5-100', 'UR1-300', 'U5-500', 'UR1-780', 'UR1-1000'],\n",
    "                'US1': ['U6-100', 'US1-300', 'U6-500', 'US1-780', 'US1-1000'],\n",
    "                'HA3': ['H1-100', 'HA3-300', 'H1-500', 'HA3-780', 'HA3-1000'],\n",
    "                'HE3': ['H2-100', 'HE3-300', 'H2-500', 'HE3-780', 'HE3-1000'],\n",
    "                'HR2': ['H5-100', 'HR2-300', 'H5-500', 'HR2-780', 'HR2-1000'],\n",
    "                'HS3': ['H6-100', 'HS3-300', 'H6-500', 'HS3-780', 'HS3-1000']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for line in samples_dict.keys():\n",
    "    all_dfs = [ancestor_df]\n",
    "    for sample in samples_dict[line]:\n",
    "        df = subset_outputgd_to_df(input_directory + sample + '.gd', sample, line, int(sample.split('-')[1]))\n",
    "        all_dfs.append(df)\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    final_df['polymorphism'] = final_df['position'].astype(str).str.cat(final_df['entry_type'], sep=' ').str.cat(final_df['mutation_detail'], sep=' ')\n",
    "    df_pvt = final_df.pivot_table(index=['genome_id', 'line', 'generation'], columns='polymorphism', values='frequency')\n",
    "    \n",
    "    #plot DvH\n",
    "    dvh_df = df_pvt.loc['NC_002937'].dropna(axis=1, how='all').fillna(0)\n",
    "    #To remove mutations that are 100% across all time points.\n",
    "    for col in dvh_df.columns:\n",
    "        if list(dvh_df[col]) == len(dvh_df[col])*[1.0]:\n",
    "            dvh_df = dvh_df.drop(col, axis=1)\n",
    "    dvh_df.plot(figsize = (20,15), legend=False, title='NC_002937: DvH Polymorphism Frequencies')\n",
    "    plt.savefig(output_directory + line + 'dvhcorrected.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #plot Mm\n",
    "    mm_df = df_pvt.loc['NC_005791'].dropna(axis=1, how='all').fillna(0)\n",
    "    #To remove mutations that are 100% across all time points.\n",
    "    for col in mm_df.columns:\n",
    "        if list(mm_df[col]) == len(mm_df[col])*[1.0]:\n",
    "            mm_df = mm_df.drop(col, axis=1)\n",
    "    mm_df.plot(figsize = (20,15), legend=False, title='NC_005791: Mm Polymorphism Frequencies')\n",
    "    plt.savefig(output_directory + line + 'mmcorrected.png')\n",
    "    plt.close()\n",
    "    \n",
    "    #plot Dv Plasmid\n",
    "    dvplasmid_df = df_pvt.loc['NC_005863'].dropna(axis=1, how='all').fillna(0)\n",
    "    #To remove mutations that are 100% across all time points.\n",
    "    for col in dvplasmid_df.columns:\n",
    "        if list(dvplasmid_df[col]) == len(dvplasmid_df[col])*[1.0]:\n",
    "            dvplasmid_df = dvplasmid_df.drop(col, axis=1)\n",
    "    \n",
    "    dvplasmid_df.plot(figsize = (20,15), legend=False, title='NC_005863: DvH Plasmid Polymorphism Frequencies')\n",
    "    plt.savefig(output_directory + line + 'dvplasmidcorrected.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For UA3 only\n",
    "samples = ['U1-100', 'UA3-300', 'U1-500', 'UE3-780', 'UE3-1000']\n",
    "\n",
    "ancestor_df = subset_outputgd_to_df(input_directory + '0.gd', 'Ancestor', 'Ancestor', 0)\n",
    "all_dfs = [ancestor_df]\n",
    "\n",
    "for each in samples:\n",
    "    df = subset_outputgd_to_df(input_directory + each + '.gd', each, 'UA3', int(each.split('-')[1]))\n",
    "    all_dfs.append(df)\n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['polymorphism'] = final_df['position'].astype(str).str.cat(final_df['entry_type'], sep=' ').str.cat(final_df['mutation_detail'], sep=' ')\n",
    "df = final_df[['line', 'genome_id', 'generation', 'polymorphism', 'frequency']].copy()\n",
    "df_pvt = df.pivot_table(index=['genome_id', 'line', 'generation'], columns='polymorphism', values='frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_df = df_pvt.loc['NC_002937'].dropna(axis=1, how='all').fillna(0)\n",
    "mm_df = df_pvt.loc['NC_005791'].dropna(axis=1, how='all').fillna(0)\n",
    "dvplasmid_df = df_pvt.loc['NC_005863'].dropna(axis=1, how='all').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove mutations that are 100% across all time points.\n",
    "for col in dvh_df.columns:\n",
    "    if list(dvh_df[col]) == len(dvh_df[col])*[1.0]:\n",
    "        dvh_df = dvh_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove mutations that are 100% across all time points.\n",
    "for col in mm_df.columns:\n",
    "    if list(mm_df[col]) == len(mm_df[col])*[1.0]:\n",
    "        mm_df = mm_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove mutations that are 100% across all time points.\n",
    "for col in dvplasmid_df.columns:\n",
    "    if list(dvplasmid_df[col]) == len(dvplasmid_df[col])*[1.0]:\n",
    "        dvplasmid_df = dvplasmid_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "dvh_df.plot(figsize = (20,15), legend=False, title='NC_002937: DvH Polymorphism Frequencies')\n",
    "plt.savefig('/Users/ymseah/Repositories/dataviz/viz/ua3dvhcorrected.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df.plot(figsize = (20,15), legend=False, title='NC_005791: Mm Polymorphism Frequencies')\n",
    "plt.savefig('/Users/ymseah/Repositories/dataviz/viz/ua3mmcorrected.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvplasmid_df.plot(figsize = (20,15), legend=False, title='NC_005863: DvH Plasmid Polymorphism Frequencies')\n",
    "plt.savefig('/Users/ymseah/Repositories/dataviz/viz/ua3dvplasmidcorrected.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sept. 22, 2017\n",
    "\n",
    "Generate input csv files (from breseq output of annotated.gd) for plotting with the following code snippets from ```lost_polymorphisms.py``` and ```plot_polymorphisms.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script from plot_polymorphisms.py\n",
    "\n",
    "from lost_polymorphisms import ComparePolymorphisms\n",
    "\n",
    "input_directory = '~/Documents/gdiff_files/'\n",
    "output_directory = '~/Repositories/dataviz/data/'\n",
    "ancestor_gd_path = input_directory + '0.gd'\n",
    "evolution_lines = ['HA3', 'HE3', 'HR2', 'HS3', 'UA3', 'UE3', 'UR1', 'US1']\n",
    "\n",
    "cp_gd = ComparePolymorphisms()\n",
    "for line in evolution_lines:\n",
    "    line_df = cp_gd.get_all_gd(line, input_directory, ancestor_gd_path)\n",
    "    output_csv = output_directory + line + '_gd_freqs.csv'\n",
    "    frequencies_df = cp_gd.gd_frequencies_to_df(line_df, save_csv=True, csv_filename=output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two relevant functions from class ComparePolymorphisms, in lost_polymorphisms.py\n",
    "\n",
    "def get_all_gd(self, evolution_line, input_directory, path_to_ancestor_gd):\n",
    "    '''\n",
    "    Input1: name of evolution line\n",
    "    Input2: directory path to all breseq results\n",
    "    Input3: path to GenomeDiff file for ancestral (generation 0) population.\n",
    "    Output: GD files for all generations of the evolution line, concatenated as one data frame.\n",
    "    '''\n",
    "    ancestor_df = self.annotated_gd_to_df(path_to_ancestor_gd, 0)\n",
    "    annotated_gd_files = glob.glob(input_directory + '*' + evolution_line + '*/output/*.gd')\n",
    "    print(annotated_gd_files)\n",
    "    all_dataframes = [ancestor_df]\n",
    "    for genome_diff in annotated_gd_files:\n",
    "        generation = int(genome_diff[-8:-3].split('-')[1])\n",
    "        dataframe = self.annotated_gd_to_df(genome_diff, generation)\n",
    "        all_dataframes.append(dataframe)\n",
    "    evolution_line_dataframe = pd.concat(all_dataframes, ignore_index=True)\n",
    "    evolution_line_dataframe.insert(0, 'line', evolution_line)\n",
    "    return evolution_line_dataframe\n",
    "\n",
    "def gd_frequencies_to_df(self, df_from_all_gd, save_csv=False, csv_filename='gd_freqs.csv'):\n",
    "    '''\n",
    "    Input: output from get_all_gd(), i.e., data frame of combined gd files from one evolution line.\n",
    "    Output: data frame of all polymorphisms with frequencies, for plotting.\n",
    "    '''\n",
    "    df_from_all_gd.insert(2, 'consensus_frequency', 'NaN')\n",
    "    df_from_all_gd.insert(3, 'polymorphism_frequency', 0.0)\n",
    "    df_from_all_gd.rename(columns = {0: 'entry_type', 1: 'item_id', 2: 'evidence_id', 3: 'genome_id', 4: 'position', 5: 'mutation_detail'}, inplace=True)\n",
    "    # entry types obtained from http://barricklab.org/twiki/pub/Lab/ToolsBacterialGenomeResequencing/documentation/gd_format.html\n",
    "    df_polymorphisms = df_from_all_gd[(df_from_all_gd['entry_type'] == 'INS') | (df_from_all_gd['entry_type'] == 'DEL') | \n",
    "            (df_from_all_gd['entry_type'] == 'SNP') | (df_from_all_gd['entry_type'] == 'SUB') | (df_from_all_gd['entry_type'] == 'MOB') | \n",
    "            (df_from_all_gd['entry_type'] == 'AMP') | (df_from_all_gd['entry_type'] == 'CON') | (df_from_all_gd['entry_type'] == 'INV')].copy()\n",
    "    for row in df_polymorphisms.itertuples():\n",
    "        for col_index in range(6, 51):\n",
    "            if re.match('frequency', str(df_polymorphisms.loc[row[0], col_index])):\n",
    "                df_polymorphisms.loc[row[0], 'polymorphism_frequency'] = re.sub('frequency=', '', str(df_polymorphisms.loc[row[0], col_index]))\n",
    "                if df_polymorphisms.loc[row[0], 'polymorphism_frequency'] == '1':\n",
    "                    df_polymorphisms.loc[row[0], 'consensus_frequency'] = 1.0\n",
    "                    evidence_id = df_polymorphisms.loc[row[0], 'evidence_id']\n",
    "                    evidence_row = df_from_all_gd[df_from_all_gd['item_id'] == evidence_id].index\n",
    "                    for evidence_col in range(6, 51):\n",
    "                        if re.match('polymorphism_frequency', str(df_from_all_gd.loc[evidence_row, evidence_col])):\n",
    "                            df_polymorphisms.loc[row[0], 'polymorphism_frequency'] = re.sub('polymorphism_frequency=', '', str(df_from_all_gd.loc[evidence_row, evidence_col]))\n",
    "                        break\n",
    "            break\n",
    "                \n",
    "    df_polymorphisms_for_plotting = df_polymorphisms[['line', 'generation', 'entry_type', 'item_id', 'mutation_detail',  \n",
    "                                                      'genome_id', 'position', 'polymorphism_frequency', 'consensus_frequency']].copy()\n",
    "    dtype = {'line': str, 'generation': int, 'entry_type': str, 'item_id': str, 'genome_id': str,\n",
    "             'position': str, 'polymorphism_frequency': float, 'consensus_frequency': float}\n",
    "    for key, value in dtype.items():\n",
    "        df_polymorphisms_for_plotting[key] = df_polymorphisms_for_plotting[key].astype(value)\n",
    "    if save_csv == True:\n",
    "        df_polymorphisms_for_plotting.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    return df_polymorphisms_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one evolution line only\n",
    "csv = '/Users/ymseah/Repositories/dataviz_scripts/sUA3_gd_freqs.csv'\n",
    "df = pd.read_csv(csv)\n",
    "df['polymorphism'] = df['position'].astype(str).str.cat(df['entry_type'], sep=' ').str.cat(df['mutation_detail'], sep=' ')\n",
    "df = df[['line', 'genome_id', 'generation', 'polymorphism', 'polymorphism_frequency']].copy()\n",
    "df_pvt = df.pivot_table(index=['genome_id', 'line', 'generation'], columns='polymorphism', values='polymorphism_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv = glob.glob('/Users/ymseah/Repositories/dataviz/data/*_gd_freqs.csv')\n",
    "df_list = []\n",
    "for csv in all_csv:\n",
    "    df = pd.read_csv(csv)\n",
    "    df_list.append(df)\n",
    "all_df = pd.concat(df_list, ignore_index=True)\n",
    "all_df['polymorphism'] = all_df['position'].astype(str).str.cat(all_df['entry_type'], sep=' ').str.cat(all_df['mutation_detail'], sep=' ')\n",
    "all_df = all_df[['line', 'genome_id', 'generation', 'polymorphism', 'polymorphism_frequency']].copy()\n",
    "all_df_pvt = all_df.pivot_table(index=['genome_id', 'line', 'generation'], columns='polymorphism', values='polymorphism_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pivoted = df_pvt\n",
    "dvh_df = pivoted.loc['NC_002937'].dropna(axis=1, how='all')\n",
    "mm_df = pivoted.loc['NC_005791'].dropna(axis=1, how='all')\n",
    "dvplasmid_df = pivoted.loc['NC_005863'].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fluctuating_bools(df):\n",
    "    '''\n",
    "    Returns 2 lists of alternating bool values. Default list length is the number of indexes in df.\n",
    "    '''\n",
    "    true_false = []\n",
    "    false_true = []\n",
    "    count = 0\n",
    "    while count < len(df.index.tolist()):\n",
    "        true_false.append(True)\n",
    "        false_true.append(False)\n",
    "        count += 1\n",
    "        if count < len(df.index.tolist()):\n",
    "            true_false.append(False)\n",
    "            false_true.append(True)\n",
    "            count += 1\n",
    "    return true_false, false_true\n",
    "\n",
    "def greater_than_last_gen(df):\n",
    "    '''Compares if frequencies in each row greater than in previous row, \n",
    "    returns df of bool values'''\n",
    "    comparisons = {}\n",
    "    count = 0\n",
    "    while count < len(df.index)-1:\n",
    "        comparisons[str(count+1) + '_to_' + str(count)] = df.loc[df.index[count+1]] > df.loc[df.index[count]]\n",
    "        count += 1\n",
    "    compare_df = pd.DataFrame(comparisons).T\n",
    "    return compare_df\n",
    "\n",
    "def subset_fluctuating_frequencies(df):\n",
    "    '''Returns list of df columns with fluctuating polymorphisms'''\n",
    "    t_f, f_t = fluctuating_bools(df)\n",
    "    fluctuating_polymorphisms = []\n",
    "    for col in df.columns:\n",
    "        if (df[col].tolist() == t_f) | (df[col].tolist() == f_t):\n",
    "            fluctuating_polymorphisms.append(col)\n",
    "    return fluctuating_polymorphisms\n",
    "\n",
    "def subset_some_fluctuation(df, tf_len=3):\n",
    "    t_f, f_t = fluctuating_bools(df)\n",
    "    some_t_f = t_f[:tf_len]\n",
    "    some_f_t = f_t[:tf_len]\n",
    "    some_flux = []\n",
    "    for col in df.columns:\n",
    "        bools_list = df[col].tolist()\n",
    "        count = 0\n",
    "        while count <= (len(bools_list)-3):\n",
    "            bools_slice = bools_list[count:(count+3)]\n",
    "            if (bools_slice == some_t_f) | (bools_slice == some_f_t):\n",
    "                some_flux.append(col)\n",
    "            count += 1\n",
    "    return list(set(some_flux))\n",
    "\n",
    "def subset_monotonic(df):\n",
    "    '''\n",
    "    Returns 2 lists of column names that have monotonically increasing, and decreasing values. \n",
    "    '''\n",
    "    mono_inc = []\n",
    "    mono_dec = []\n",
    "    for col in df.columns:\n",
    "        if df[col].is_monotonic_increasing:\n",
    "            mono_inc.append(col)\n",
    "        elif df[col].is_monotonic_decreasing:\n",
    "            mono_dec.append(col)\n",
    "    return mono_inc, mono_dec\n",
    "\n",
    "# Plotting functions\n",
    "\n",
    "def plot_fluctuating(df, some_flux=False, flux_len=3):\n",
    "    compare_freqs = greater_than_last_gen(df)\n",
    "    if some_flux == False:\n",
    "        flux = subset_fluctuating_frequencies(compare_freqs)\n",
    "    else:\n",
    "        flux = subset_some_fluctuation(compare_freqs, tf_len = flux_len)\n",
    "    df[flux].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)   \n",
    "\n",
    "def plot_line_summary(line, df, plottitle):\n",
    "    data = df.loc[line.upper()].dropna(axis=1, how='all').fillna(0)\n",
    "    # monotonic\n",
    "    inc, dec = subset_monotonic(data)\n",
    "    fig, axes = plt.subplots(5,1, sharex=True)\n",
    "    if len(inc) > 0:\n",
    "        data[inc].plot(ax=axes[0], legend=False, title=plottitle)\n",
    "    else:\n",
    "        axes[0].set_title(plottitle)\n",
    "    if len(dec) > 0:\n",
    "        data[dec].plot(ax=axes[1], legend=False)\n",
    "    # all fluctuating\n",
    "    compare_freqs = greater_than_last_gen(data)\n",
    "    flux = subset_fluctuating_frequencies(compare_freqs)\n",
    "    if len(flux) > 0:\n",
    "        data[flux].plot(ax=axes[2], legend=False)\n",
    "    # some fluctuating\n",
    "    flux2 = subset_some_fluctuation(compare_freqs)\n",
    "    for each in flux:\n",
    "        flux2.remove(each)\n",
    "    if len(flux2) > 0:\n",
    "        data[flux2].plot(ax=axes[3], legend=False)\n",
    "    # others\n",
    "    oth = []\n",
    "    for col in data.columns:\n",
    "        if (col not in inc) & (col not in dec) & (col not in flux) & (col not in flux2):\n",
    "            oth.append(col)\n",
    "    if len(oth) > 0:\n",
    "        data[oth].plot(ax=axes[4], legend=False)\n",
    "    plt.savefig(plottitle + '_summary.png')\n",
    "\n",
    "def plot_line_individual(line, df, genome_id):\n",
    "    data = df.loc[line.upper()].dropna(axis=1, how='all').fillna(0)\n",
    "    inc, dec = subset_monotonic(data)\n",
    "    compare_freqs = greater_than_last_gen(data)\n",
    "    flux = subset_fluctuating_frequencies(compare_freqs)\n",
    "    flux2 = subset_some_fluctuation(compare_freqs)\n",
    "    for each in flux:\n",
    "        flux2.remove(each)\n",
    "\n",
    "    if len(inc) > 0:\n",
    "        data[inc].plot(title = line.upper() + ':' + genome_id + ' is_monotonic_increasing', figsize=(20,15)).legend(loc='upper left', ncol=6)\n",
    "        plt.savefig(line.upper() + '_' + genome_id + '_monotonic_increasing.png')\n",
    "    if len(dec) > 0:\n",
    "        data[dec].plot(title = line.upper() + ':' + genome_id + ' is_monotonic_decreasing', figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "        plt.savefig(line.upper() + '_' + genome_id + '_monotonic_decreasing.png')\n",
    "    if len(flux) > 0:\n",
    "        data[flux].plot(title = line.upper() + ':' + genome_id + ' fluctuating', figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "        plt.savefig(line.upper() + '_' + genome_id + '_fluctuating.png')\n",
    "    if len(flux2) > 0:\n",
    "        data[flux2].plot(title = line.upper() + ':' + genome_id + ' some fluctuating', figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "        plt.savefig(line.upper() + '_' + genome_id + '_some_fluctuating.png')\n",
    "\n",
    "    oth = []\n",
    "    for col in data.columns:\n",
    "        if (col not in inc) & (col not in dec) & (col not in flux) & (col not in flux2):\n",
    "            oth.append(col)\n",
    "    if len(oth) > 0:\n",
    "        data[oth].plot(title = line.upper() + ':' + genome_id + ' others', figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "        plt.savefig(line.upper() + '_' + genome_id + '_others.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_line_summary('ua3', dvh_df, 'sUA3-NC_002937')\n",
    "plot_line_summary('ua3', mm_df, 'sUA3-NC_005791')\n",
    "plot_line_summary('ua3', dvplasmid_df, 'sUA3-NC_005863')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh_df.dropna(axis=1, how='all').fillna(0)\n",
    "ua3dvh.plot(figsize = (20,15)).legend(loc='upper right', ncol=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_line_individual('ua3', dvh_df, 'NC_002937')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_individual('ua3', mm_df, 'NC_005791')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_individual('ua3', dvplasmid_df, 'NC_005863')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ua3dvh = dvh_df.loc['UA3'].dropna(axis=1, how='all').fillna(0)\n",
    "ua3dvh_compare = greater_than_last_gen(ua3dvh)\n",
    "plot_fluctuating(ua3dvh, some_flux=True)\n",
    "plt.savefig('ua3dvh_flux.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua3dvh_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua3dvh.plot(figsize = (20,15)).legend(loc='upper right', ncol=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peak1=[]\n",
    "peak2=[]\n",
    "peak3=[]\n",
    "peak4=[]\n",
    "peak5=[]\n",
    "for polym in ua3dvh_compare.columns.tolist():\n",
    "    if ua3dvh_compare.loc['1_to_0', polym] == True:\n",
    "        peak1.append(polym)\n",
    "    if ua3dvh_compare.loc['2_to_1', polym] == True:\n",
    "        peak2.append(polym)\n",
    "    if ua3dvh_compare.loc['3_to_2', polym] == True:\n",
    "        peak3.append(polym)\n",
    "    if ua3dvh_compare.loc['4_to_3', polym] == True:\n",
    "        peak4.append(polym)\n",
    "    if ua3dvh_compare.loc['5_to_4', polym] == True:\n",
    "        peak5.append(polym)\n",
    "\n",
    "others=[]\n",
    "peak_all = set(peak1 + peak2 + peak3 + peak4 + peak5)\n",
    "for polym in ua3dvh_compare.columns.tolist():\n",
    "    if polym not in peak_all:\n",
    "        others.append(polym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua3dvh[others].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_peak_none.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_polymorphisms = subset_some_fluctuation(ua3dvh_compare)\n",
    "ua3dvh_flux = ua3dvh_compare[flux_polymorphisms].T\n",
    "#ua3dvh_flux\n",
    "ftfff = ua3dvh_flux[(ua3dvh_flux['1_to_0'] == False) & (ua3dvh_flux['2_to_1'] == True) & \n",
    "           (ua3dvh_flux['3_to_2'] == False) & (ua3dvh_flux['4_to_3'] == False) & (ua3dvh_flux['5_to_4'] == False)]\n",
    "ua3dvh[ftfff.index.tolist()].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_ftfff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftftf = ua3dvh_flux[(ua3dvh_flux['1_to_0'] == False) & (ua3dvh_flux['2_to_1'] == True) & \n",
    "           (ua3dvh_flux['3_to_2'] == False) & (ua3dvh_flux['4_to_3'] == True) & (ua3dvh_flux['5_to_4'] == False)]\n",
    "ua3dvh[ftftf.index.tolist()].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_ftftf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftff = ua3dvh_flux[(ua3dvh_flux['1_to_0'] == False) & (ua3dvh_flux['2_to_1'] == False) & \n",
    "           (ua3dvh_flux['3_to_2'] == True) & (ua3dvh_flux['4_to_3'] == False) & (ua3dvh_flux['5_to_4'] == False)]\n",
    "ua3dvh[fftff.index.tolist()].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_fftff.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffftf = ua3dvh_flux[(ua3dvh_flux['1_to_0'] == False) & (ua3dvh_flux['2_to_1'] == False) & \n",
    "           (ua3dvh_flux['3_to_2'] == False) & (ua3dvh_flux['4_to_3'] == True) & (ua3dvh_flux['5_to_4'] == False)]\n",
    "ua3dvh[ffftf.index.tolist()].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_ffftf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others = []\n",
    "for row in ua3dvh_flux.index.tolist():\n",
    "    if (row not in ftfff.index.tolist()) & (row not in ftftf.index.tolist()) & (row not in fftff.index.tolist()) & (row not in ffftf.index.tolist()):\n",
    "        others.append(row)\n",
    "ua3dvh[others].plot(figsize=(20,15)).legend(loc='upper right', ncol=6)\n",
    "plt.savefig('ua3dvh_others.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R/RStudio envy resulted in...\n",
    "\n",
    "R code to tidy and plot data initially, with much help from [R for Data Science](http://r4ds.had.co.nz/tidy-data.html#missing-values-3). ~~Will rewrite this in Python, once I've learned it!~~ *Done!*\n",
    "\n",
    "```\n",
    "# In plotfreqs.R\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "get_polymorphisms <- function(filepath) {\n",
    "  polymorphisms <- read.csv(filepath) %>% \n",
    "    unite(polymorphism, position, entry_type, mutation_detail, sep = ' ') %>%\n",
    "    select(genome_id, polymorphism, generation, polymorphism_frequency) %>% \n",
    "    complete(nesting(polymorphism, genome_id), generation, fill = list(polymorphism_frequency = 0))\n",
    "  return(polymorphisms)\n",
    "}\n",
    "\n",
    "plot_polymorphism_frequencies <- function(polymorphism_tibble, output_dir) {\n",
    "  ggplot(data = polymorphism_tibble, mapping = aes(x = generation, y = polymorphism_frequency)) + \n",
    "    geom_line(aes(group = polymorphism)) + \n",
    "    facet_wrap(~ genome_id, ncol = 1)\n",
    "  ggsave(paste(output_dir, 'polymorphism_plot.png', sep = ''), last_plot())\n",
    "}\n",
    "\n",
    "# In plot_genotypes.R\n",
    "\n",
    "source('~/plotfreqs.R')\n",
    "\n",
    "ue3polymorphisms = get_polymorphisms('~/data/UE3_gd_freqs.csv')\n",
    "write.csv(ue3polymorphisms, file = '~/ue3polymorphisms.csv', row.names = FALSE, quote = FALSE)\n",
    "plot_polymorphism_frequencies(ue3polymorphisms, '~/viz/')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
