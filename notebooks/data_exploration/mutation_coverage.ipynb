{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_cov(cov_str):\n",
    "    cov_ints = cov_str.split('/')\n",
    "    total_cov = 0\n",
    "    for cov in cov_ints:\n",
    "        total_cov += int(cov)\n",
    "    return total_cov\n",
    "\n",
    "def subset_gd_to_df(gdfile, sample_name, line, generation=np.nan, cov=False):\n",
    "    '''\n",
    "    Default returns one dataframe created from annotated.gd. All mutation rows are preserved,\n",
    "    but only selected variables from each row, namely entry type, entry id, \n",
    "    evidence id, genome id, position, mutation detail, frequency, and gene product.\n",
    "    \n",
    "    If cov=True, will return TWO dataframes, the first as above, the second reporting \n",
    "    entry type, entry id, evidence id, genome id, position,reject reasons, prediction mode, \n",
    "    polymorphism frequencies, major and minor coverages (i.e., major_cov, minor_cov), \n",
    "    total coverage (total_cov), RA coverage (new_cov), JC coverage (new_junction_read_count), \n",
    "    and MC-flanking coverage (left_outside_cov + right_outside_cov).\n",
    "    '''\n",
    "    df = pd.read_csv(gdfile, comment='#', names=range(200), dtype=str, sep='\\t')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    # https://stackoverflow.com/questions/27700591/reading-csv-files-with-messy-structure-with-pandas\n",
    "    num_columns = len(df.columns)\n",
    "    df.rename(columns = {0: 'entry_type', 1: 'entry_id', 2: 'evidence_id', \n",
    "                         3: 'genome_id', 4: 'position', 5: 'mutation_detail'}, inplace=True)\n",
    "\n",
    "    df_mutations = df[(df['entry_type'] == 'INS') | (df['entry_type'] == 'DEL') | \n",
    "                      (df['entry_type'] == 'SNP') | (df['entry_type'] == 'SUB') | \n",
    "                      (df['entry_type'] == 'MOB') | (df['entry_type'] == 'AMP') | \n",
    "                      (df['entry_type'] == 'CON') | (df['entry_type'] == 'INV')].copy()\n",
    "    \n",
    "    for row in df_mutations.index:\n",
    "        #check each column\n",
    "        mut_col_index = 6\n",
    "        while mut_col_index < num_columns:\n",
    "            #1. mutation frequencies\n",
    "            if re.match('frequency=', str(df_mutations.loc[row, mut_col_index])):\n",
    "                df_mutations.loc[row, 'frequency'] = re.sub('frequency=', '', str(df_mutations.loc[row, mut_col_index]))\n",
    "                if df_mutations.loc[row, 'frequency'] == 'NA':\n",
    "                    df_mutations.loc[row, 'frequency'] = np.nan\n",
    "            #2. gene products\n",
    "            elif re.match('gene_product=', str(df_mutations.loc[row, mut_col_index])):\n",
    "                df_mutations.loc[row, 'gene_product'] = re.sub('gene_product=', '', str(df_mutations.loc[row, mut_col_index]))\n",
    "            mut_col_index += 1\n",
    "\n",
    "    df_mutations = df_mutations[['entry_type', 'entry_id', 'evidence_id', 'genome_id', \n",
    "                             'position', 'mutation_detail', 'frequency', 'gene_product']].copy()\n",
    "    \n",
    "    #insert sample name, line, and generation\n",
    "    df_mutations.insert(0, 'sample', sample_name)\n",
    "    df_mutations.insert(1, 'line', line)\n",
    "    df_mutations.insert(2, 'generation', generation)\n",
    "    #set frequencies type to float\n",
    "    df_mutations['frequency'] = df_mutations['frequency'].astype(float)\n",
    "\n",
    "    if cov == True:\n",
    "        df_evidence = df[(df['entry_type'] == 'RA') | (df['entry_type'] == 'JC') | \n",
    "                         (df['entry_type'] == 'MC') | (df['entry_type'] == 'UN')].copy()\n",
    "        df_evidence.rename(columns = {6: 'REF', 7: 'ALT'}, inplace=True)\n",
    "\n",
    "        for row in df_evidence.index:\n",
    "            col_index = 8\n",
    "            while col_index < num_columns:\n",
    "                #3. polymorphism rejection reasons\n",
    "                if re.match('reject=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'reject'] = re.sub('reject=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #4. prediction type\n",
    "                elif re.match('prediction=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'prediction'] = re.sub('prediction=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #5. polymorphism mode frequencies\n",
    "                elif re.match('polymorphism_frequency=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'polymorphism_frequency'] = re.sub('polymorphism_frequency=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if df_evidence.loc[row, 'polymorphism_frequency'] == 'NA':\n",
    "                        df_evidence.loc[row, 'polymorphism_frequency'] = np.nan\n",
    "                #6. major coverage counts\n",
    "                elif re.match('major_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    major_cov = re.sub('major_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'major_cov'] = sum_cov(major_cov)\n",
    "                #7. minor coverage counts\n",
    "                elif re.match('minor_cov', str(df_evidence.loc[row, col_index])):\n",
    "                    minor_cov = re.sub('minor_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'minor_cov'] = sum_cov(minor_cov)\n",
    "                #8. total coverage counts\n",
    "                elif re.match('total_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    total_cov = re.sub('total_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'total_cov'] = sum_cov(total_cov)\n",
    "                #9. read alignment coverage counts\n",
    "                elif re.match('new_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    ra_cov = re.sub('new_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    df_evidence.loc[row, 'ra_cov'] = sum_cov(ra_cov)\n",
    "                #10. new junction coverage counts\n",
    "                elif re.match('new_junction_read_count=', str(df_evidence.loc[row, col_index])):\n",
    "                    df_evidence.loc[row, 'jc_cov'] = re.sub('new_junction_read_count=', '', str(df_evidence.loc[row, col_index]))\n",
    "                #11. flanking coverage counts for missing coverage evidence\n",
    "                elif re.match('left_outside_cov=', str(df_evidence.loc[row, col_index])):\n",
    "                    left_cov = re.sub('left_outside_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if left_cov == 'NA':\n",
    "                        left_cov = 0\n",
    "                    else:\n",
    "                        df_evidence.loc[row, 'left_cov'] = int(left_cov)\n",
    "                elif re.match('right_outside_cov', str(df_evidence.loc[row, col_index])):\n",
    "                    right_cov = re.sub('right_outside_cov=', '', str(df_evidence.loc[row, col_index]))\n",
    "                    if right_cov == 'NA':\n",
    "                        right_cov = 0\n",
    "                    else:\n",
    "                        df_evidence.loc[row, 'right_cov'] = int(right_cov)\n",
    "                col_index += 1\n",
    "        \n",
    "        #set missing coverage col to 'NA' if no evidence\n",
    "        if 'left_cov' in df_evidence.columns and 'right_cov' in df_evidence.columns:\n",
    "            df_evidence[['left_cov', 'right_cov']].fillna(0)\n",
    "            df_evidence['mc_cov'] = df_evidence.left_cov + df_evidence.right_cov\n",
    "        else:\n",
    "            df_evidence['mc_cov'] = np.nan        \n",
    "        #set reject col to 'NA' when no reject reason given.\n",
    "        if 'reject' in df_evidence.columns:\n",
    "            if (df_evidence.loc[row, 'reject'] == '') & (df_evidence.loc[row, 'evidence_id'] == '.'):\n",
    "                df_evidence.loc[row, 'reject'] = np.nan\n",
    "        else:\n",
    "            df_evidence['reject'] = np.nan\n",
    "        \n",
    "        df_evidence = df_evidence[['entry_type', 'entry_id', 'genome_id', 'position', 'REF', 'ALT',\n",
    "                     'reject', 'prediction', 'polymorphism_frequency', 'major_cov', 'minor_cov', \n",
    "                     'total_cov', 'ra_cov', 'jc_cov', 'mc_cov']].copy()\n",
    "        \n",
    "        #insert sample name, line and generation\n",
    "        df_evidence.insert(0, 'sample', sample_name)\n",
    "        df_evidence.insert(1, 'line', line)\n",
    "        df_evidence.insert(2, 'generation', generation)\n",
    "        #set frequencies type to float\n",
    "        df_evidence['polymorphism_frequency'] = df_evidence['polymorphism_frequency'].astype(float)\n",
    "        \n",
    "        return df_mutations, df_evidence\n",
    "\n",
    "    else:\n",
    "        return df_mutations\n",
    "    \n",
    "def combine_mutations_and_evidence(df_mutations, df_evidence):\n",
    "    for evidence in df_mutations['evidence_id']:\n",
    "        multi_evidence = evidence.split(',')\n",
    "        count = 0\n",
    "        while count < len(multi_evidence):\n",
    "            mutation_row_index = df_mutations[df_mutations['evidence_id'] == evidence].index[0]\n",
    "            df_mutations.loc[mutation_row_index, 'evidence_type'] = df_evidence.loc[int(multi_evidence[count])-1, 'entry_type']\n",
    "            df_mutations.loc[mutation_row_index, 'REF'] = df_evidence.loc[int(multi_evidence[count])-1, 'REF']\n",
    "            df_mutations.loc[mutation_row_index, 'ALT'] = df_evidence.loc[int(multi_evidence[count])-1, 'ALT']\n",
    "            df_mutations.loc[mutation_row_index, 'reject'] = df_evidence.loc[int(multi_evidence[count])-1, 'reject']\n",
    "            df_mutations.loc[mutation_row_index, 'prediction'] = df_evidence.loc[int(multi_evidence[count])-1, 'prediction']\n",
    "            df_mutations.loc[mutation_row_index, 'polymorphism_frequency'] = df_evidence.loc[int(multi_evidence[count])-1, 'polymorphism_frequency']\n",
    "            df_mutations.loc[mutation_row_index, 'major_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'major_cov']\n",
    "            df_mutations.loc[mutation_row_index, 'minor_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'minor_cov']\n",
    "            df_mutations.loc[mutation_row_index, 'total_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'total_cov']\n",
    "            df_mutations.loc[mutation_row_index, 'ra_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'ra_cov']\n",
    "            df_mutations.loc[mutation_row_index, 'jc_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'jc_cov']\n",
    "            df_mutations.loc[mutation_row_index, 'mc_cov'] = df_evidence.loc[int(multi_evidence[count])-1, 'mc_cov']\n",
    "            count += 1\n",
    "    return df_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mutation and evidence dataframes\n",
    "d2mut, d2evidence = subset_gd_to_df('/Users/ymseah/Repositories/dvh_mms2/depth_mle/d2/annotated.gd', 'D2-0', 'D2', '0', cov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1mut, m1evidence = subset_gd_to_df('/Users/ymseah/Repositories/dvh_mms2/depth_mle/m1/annotated.gd', 'M1-0', 'M1', '0', cov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d2mut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2evidence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add evidence to mutations dataframe\n",
    "new_d2mut = combine_mutations_and_evidence(d2mut, d2evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_m1mut = combine_mutations_and_evidence(m1mut, m1evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_d2mut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2m1 = pd.concat([new_d2mut, new_m1mut], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d2m1RA = d2m1[d2m1['evidence_type'] == 'RA']\n",
    "freqs_df = d2m1RA[['genome_id', 'position', 'REF', 'ALT', 'sample', 'polymorphism_frequency']]\n",
    "pvt_freqs = freqs_df.pivot_table(index=['genome_id', 'position', 'REF', 'ALT'], columns='sample', values='polymorphism_frequency')\n",
    "pvt_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_df = d2m1RA[['genome_id', 'position', 'REF', 'ALT', 'sample', 'ra_cov']]\n",
    "pvt_cov = cov_df.pivot_table(index=['genome_id', 'position', 'REF', 'ALT'], columns='sample', values='ra_cov').fillna(0)\n",
    "pvt_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coverage.csv', 'w') as cov:\n",
    "    header = '#CHROM,POS,REF,ALT,'\n",
    "    count = 0\n",
    "    while count < len(pvt_cov.columns) - 1:\n",
    "        header += pvt_cov.columns[count] + ','\n",
    "        count += 1\n",
    "    header += pvt_cov.columns[count] + '\\n'\n",
    "    cov.write(header)\n",
    "    for row in pvt_cov.index:\n",
    "        cov.write(row[0] + ',' + row[1] + ',' + row[2] + ',' + row[3] + ',')\n",
    "        sample_count = 0\n",
    "        while sample_count < len(pvt_cov.columns) - 1:\n",
    "            cov.write(str(pvt_cov.loc[row, pvt_cov.columns[sample_count]]) + ',')\n",
    "            sample_count += 1\n",
    "        cov.write(str(pvt_cov.loc[row, pvt_cov.columns[sample_count]]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('freqs.csv', 'w') as freqs:\n",
    "    header = '#CHROM,POS,REF,ALT,'\n",
    "    count = 0\n",
    "    while count < len(pvt_freqs.columns) - 1:\n",
    "        header += pvt_freqs.columns[count] + ','\n",
    "        count += 1\n",
    "    header += pvt_freqs.columns[count] + '\\n'\n",
    "    freqs.write(header)\n",
    "    for row in pvt_freqs.index:\n",
    "        freqs.write(row[0] + ',' + row[1] + ',' + row[2] + ',' + row[3] + ',')\n",
    "        sample_count = 0\n",
    "        while sample_count < len(pvt_freqs.columns) - 1:\n",
    "            freqs.write(str(pvt_freqs.loc[row, pvt_freqs.columns[sample_count]]) + ',')\n",
    "            sample_count += 1\n",
    "        freqs.write(str(pvt_freqs.loc[row, pvt_freqs.columns[sample_count]]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('samples.csv', 'w') as sample_list:\n",
    "    sample_list.write('Name,Population,Generation\\n')\n",
    "    samples_df = d2m1[['sample', 'line', 'generation']].drop_duplicates()\n",
    "    for row in samples_df.index:\n",
    "        sample_list.write(samples_df.loc[row, 'sample'] + ',' + samples_df.loc[row, 'line'] + ',' + str(samples_df.loc[row, 'generation'] + '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
